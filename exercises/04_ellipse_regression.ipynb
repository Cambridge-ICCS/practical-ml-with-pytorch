{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression with a CNN\n",
    "\n",
    "In the previous exercise we used a CNN model to solve a classification problem—namely MNIST handwritten digits.\n",
    "\n",
    "In this exercise we will used the same model to solve a regression problem; estimating the centroid $(x_{\\text{c}}, y_{\\text{c}})$, and the major/minor radii $r_{x}$ and $r_{y}$ of an ellipse.  \n",
    "\n",
    "Recall: an ellipse is defined by\n",
    "$$\n",
    "\\frac{(x - x_{\\text{c}})^{2}}{r_{x}^{2}} + \\frac{(y - y_{\\text{c}})^{2}}{r_{y}^{2}} = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Accessing some data\n",
    "\n",
    "For this project, we have created a very simple dataset which yields an image of an ellipse, with the various parameters that define it as targets to learn.\n",
    "\n",
    "This code can be found in ``src/ml_workshop/_ellipse.py``, though understanding it is not necessary for the exercises (that said, it is very simple)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_workshop import EllipseDataset\n",
    "\n",
    "dataset = EllipseDataset(training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the data, and how they are presented to us, the easiest thing to do is to plot them. Let's obtain five input--target pairs, plot the images, and overlay the target information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "for idx in range(5):\n",
    "    pairs.append(dataset[idx])\n",
    "\n",
    "# If you have a list of tuples, you \"unzip\" them into individual lists this way\n",
    "imgs, targets = zip(*pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What types does the image data have?\n",
    "- What types does the target data have?\n",
    "- How is the data presented to us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The images are of type '{type(imgs[0])}'\")\n",
    "print(f\"The targets are of type '{type(targets[0])}'\")\n",
    "\n",
    "print(f\"The images have shape '{imgs[0].shape}'\")\n",
    "print(f\"The targets have shape '{targets[0].shape}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The images are RGB arrays of shape ``(height, width, colour_channels)``.\n",
    "- The targets are arrays holding the coordinate information:\n",
    "  - ``(row_center, col_center, row_radius, col_radius)``.\n",
    "  - There are the four parameters required to define an ellipse.\n",
    "\n",
    "\n",
    "\n",
    "Let us now plot the images, and overlay the target information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "figure, axes = plt.subplots(1, len(pairs), figsize=(16, 4))\n",
    "\n",
    "for x, y, axis in zip(imgs, targets, axes.ravel()):\n",
    "    axis.imshow(x, extent=(0, 1, 1, 0))\n",
    "    axis.errorbar(\n",
    "        y[1],\n",
    "        y[0],\n",
    "        xerr=y[3],\n",
    "        yerr=y[2],\n",
    "        marker=\"o\",\n",
    "        color=\"k\",\n",
    "        capsize=10,\n",
    "    )\n",
    "    axis.set_title(f\"Centroid: ({y[1]:.2f}, {y[0]:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: The coordinate information is always expressed in fractions of the linear dimension of the images, so we don't need to worry about normalising the data, and we have natural bounds for the interval on which our predictions should lie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: ``Dataset`` $\\to$ ``DataLoader``\n",
    "\n",
    "As before, wrap the ``Dataset``s in ``DataLoader``s.\n",
    "\n",
    "- First, reinstantiate the datasets, then provide ``Compose`` objects containing the transforms required to map from numpy arrays to torch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, ToTensor\n",
    "from torch import from_numpy\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_set = EllipseDataset(\n",
    "    training=True,\n",
    "    # input_tfms=???,\n",
    "    # target_tfms=???,\n",
    ")\n",
    "valid_set = EllipseDataset(\n",
    "    training=False,\n",
    "    # input_tfms=???,\n",
    "    # target_tfms=???,\n",
    ")\n",
    "\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Choose a model architecture\n",
    "\n",
    "Let's use the same CNN as we did before (``MOBILENET`` small) since it's relatively lightweight.\n",
    "\n",
    "- Instantiate the model and print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import mobilenet_v3_small\n",
    "from torchvision.models import MobileNet_V3_Small_Weights\n",
    "\n",
    "model = mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.DEFAULT)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5: Uh oh, we've a problem—again.\n",
    " - The model again has 1000 output features.\n",
    "   - How many do we need?\n",
    "- Modify the number of output features, as we did in the previous exercise, accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "\n",
    "# model.classifier[3] = Linear(model.classifier[3].in_features, ???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Set up the remaining PyTorch bits and bobs\n",
    "\n",
    "- We need to choose a loss function appropriate for _regression_.\n",
    "  - Can you remember what we chose previously?\n",
    "- We need an optimiser, too.\n",
    "  - Remember our friend, Adam?\n",
    "- Instantiate the model and loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.nn import MSELoss\n",
    "# from torch.optim import Adam\n",
    "\n",
    "# loss_func = MSELoss(???)\n",
    "\n",
    "# optimiser = Adam(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Set the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.cuda as cuda\n",
    "import torch.xpu as xpu\n",
    "import torch.backends.mps as mps\n",
    "\n",
    "if cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "elif xpu.is_available():\n",
    "    DEVICE = \"xpu\"\n",
    "elif mps.is_available():\n",
    "    DEVICE = \"mps\"\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "\n",
    "print(DEVICE)\n",
    "\n",
    "# Note: here the return/assignment to ``_`` is just to suppress the print.\n",
    "# The model is moved onto the correct device in-place.\n",
    "_ = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7: Writing our training and validation loops\n",
    "\n",
    "As before, we need to write our training and validation loops.\n",
    "\n",
    "- Complete the training loop\n",
    "- Complete the validation loop\n",
    "- What metrics can we extract in a regression problem?\n",
    "\n",
    "\n",
    "Things to consider:\n",
    "- Using the ``ReLU`` activation function to stop our outputs being negative.\n",
    "    - Since the quantities we are estimating lie on the interval [0, 1], and we are dealing with coordinates we don't want to be negative, it makes sense to apply the ``ReLU`` activation function.\n",
    "- Any other activation functions might we use to bound our outputs?\n",
    "    - Technically, we might use the Sigmoid, which would bound our inputs to (0, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from torch import no_grad\n",
    "from torch.nn import Module\n",
    "\n",
    "\n",
    "def train_one_epoch(\n",
    "    model: Module,\n",
    "    train_loader: DataLoader,\n",
    "    optimiser: Adam,\n",
    "    loss_func: MSELoss,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Train the model for a single epoch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : Module\n",
    "        A neural network.\n",
    "    train_loader : DataLoader\n",
    "        The ``DataLoader`` for the training set.\n",
    "    optimiser : Adam\n",
    "        The optimiser to update the model's parameters with.\n",
    "    loss_func : BCELoss\n",
    "        Binary-cross-entropy loss function.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, float]\n",
    "        A dictionary of metrics.\n",
    "\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    metrics = {\"loss\": []}\n",
    "\n",
    "    for batch, targets in train_loader:\n",
    "        pass\n",
    "\n",
    "\n",
    "@no_grad()\n",
    "def validate_one_epoch(\n",
    "    model: Module,\n",
    "    valid_loader: DataLoader,\n",
    "    loss_func: MSELoss,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Validate the model for a single epoch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : Module\n",
    "        A neural network.\n",
    "    valid_loader : DataLoader\n",
    "        The ``DataLoader`` for the validation set.\n",
    "    loss_func : BCELoss\n",
    "        Binary-cross-entropy loss function.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, float]\n",
    "        A dictionary of metrics.\n",
    "\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    metrics = {\"loss\": []}\n",
    "\n",
    "    for batch, targets in train_loader:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8: Training, extracting and plotting metrics\n",
    "\n",
    "- Now we can train our model for a specified number of epochs.\n",
    "  - During each epoch the model \"sees\" each training item once.\n",
    "- Append the training and validation metrics to a list.\n",
    "- Turn them into a ``pandas.DataFrame``\n",
    "  - Note: You can turn a ``List[Dict[str, float]]``, say ``my_list`` into a ``DataFrame`` with ``DataFrame(my_list)``.\n",
    "- Use Matplotlib to plot the training and validation metrics as a function of the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "epochs = 25\n",
    "\n",
    "train_metrics, valid_metrics = [], []\n",
    "\n",
    "for _ in range(epochs):\n",
    "    # Let's call our training and validation functions, and store their output\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9: Plotting our metrics\n",
    "\n",
    "- Plot the loss for the training and validation sets at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axis = plt.subplots(1, 1)\n",
    "\n",
    "# axis.plot(???, \"-o\", label=\"Training loss\")\n",
    "# axis.plot(???, \"-o\", label=\"Validation loss\")\n",
    "\n",
    "# axis.set_yscale(\"log\")\n",
    "\n",
    "# axis.legend()\n",
    "\n",
    "# axis.set_xlabel(\"Epoch\")\n",
    "# axis.set_ylabel(\"MSE Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10: Visualising some results\n",
    "\n",
    "- When we first looked at the data, we plotted the images and overlayed the coordinate information.\n",
    "  - Let's do this again, now using the model's predictions rather than the ground truths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This simply grabs us one mini-batch of data.\n",
    "batch, targets = next(iter(valid_loader))\n",
    "\n",
    "model = model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "with no_grad():\n",
    "    pass\n",
    "    # preds = model(batch).??? — what activation should we use?\n",
    "\n",
    "figure, axes = plt.subplots(1, len(preds), figsize=(len(preds) * 2.5, 2.5))\n",
    "\n",
    "for image, pred, axis in zip(batch, preds, axes.ravel()):\n",
    "    axis.imshow(image.permute(1, 2, 0), extent=(0, 1, 1, 0))\n",
    "    axis.errorbar(\n",
    "        pred[1].item(),\n",
    "        pred[0].item(),\n",
    "        marker=\"o\",\n",
    "        yerr=pred[2].item(),\n",
    "        xerr=pred[3].item(),\n",
    "        color=\"k\",\n",
    "        capsize=10,\n",
    "    )\n",
    "\n",
    "    axis.set_xlim(left=0.0, right=1.0)\n",
    "    axis.set_ylim(bottom=0.0, top=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 11\n",
    "\n",
    "- Re-run the previous cell over and over.\n",
    "- Do the results look good, or not?\n",
    "- Train the model for longer—say 50 epochs—and re-evaluate.\n",
    "- Head off into the sunset with a smile at your new-found skills in implementing machine learning.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
